{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory set to: c:\\Users\\Biebert\\OneDrive - Universit√§t St.Gallen\\Dokumente\\OneDrive Dokumente\\02_Bildung\\01_BVWL Bachelor\\01_Kurse\\07_Thesis\\Code\\Portfolio_Optimization_DDPG\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)  # Set the seed for reproducibility\n",
    "\n",
    "# Check if the original directory is already saved in a variable\n",
    "if 'original_directory' not in globals():\n",
    "    # Save the original working directory the first time\n",
    "    original_directory = os.getcwd()\n",
    "\n",
    "# Change back to the original directory whenever the cell is executed\n",
    "os.chdir(original_directory)\n",
    "\n",
    "# Go to mother directory\n",
    "os.chdir(\"../\")\n",
    "\n",
    "# Verify the current working directory\n",
    "print(\"Working directory set to:\", os.getcwd())\n",
    "\n",
    "sys.path.append(os.path.abspath(os.getcwd()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_scripts import generate_data as gd\n",
    "# Get the list of S&P 500 stocks\n",
    "\n",
    "np.random.seed(4)\n",
    "\n",
    "if not os.path.exists(\"data/stock_overview.csv\"):\n",
    "    sp500_tickers = gd.get_sp500_stocks()\n",
    "    data_dict = gd.filter_liquid_stocks(sp500_tickers)\n",
    "    data_frame_df = pd.DataFrame.from_dict(data_dict, orient='index').transpose()\n",
    "    data_frame_df.to_csv(\"data/stock_overview.csv\", index=False)\n",
    "else:\n",
    "    liquid_stocks_df = pd.read_csv(\"data/stock_overview.csv\")\n",
    "\n",
    "valid_stocks  = liquid_stocks_df['Liquid Stocks'].dropna()\n",
    "tickers = valid_stocks.sample(5).tolist()\n",
    "tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_scripts import plotting as pl\n",
    "\n",
    "pl.plot_original_stock(tickers = tickers, start_date=\"2000-01-01\", end_date=\"2024-01-01\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_simulation_episodes = 100\n",
    "num_simulation_days = 750\n",
    "tickers = ['MSFT', 'TGT', 'QCOM', 'MU', 'CAT']\n",
    "\n",
    "from data_scripts import generate_data as gd\n",
    "from data_scripts import plotting as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_scripts import generate_data as gd\n",
    "tickers = ['MSFT', 'TGT', 'QCOM', 'MU', 'CAT']\n",
    "\n",
    "data = gd.download_data(tickers, \"2000-01-01\", \"2023-12-31\")\n",
    "log_returns = gd.create_log_return(data=data)\n",
    "\n",
    "train, test = gd.stock_train_test_split(returns=log_returns)\n",
    "\n",
    "\n",
    "\n",
    "# Save\n",
    "train.to_csv(\"data/train_data.csv\")\n",
    "test.to_csv(\"data/test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train_data.csv\", index_col=0)\n",
    "test = pd.read_csv(\"data/test_data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from arch import arch_model\n",
    "import yfinance as yf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "\n",
    "def download_data(tickers, start_date, end_date):\n",
    "    data = yf.download(tickers, start=start_date, end=end_date)['Adj Close']\n",
    "    return data\n",
    "\n",
    "def create_log_return(data):\n",
    "    log_returns = np.log(data / data.shift(1)).dropna()\n",
    "    return log_returns\n",
    "\n",
    "def save_data_csv(data, filename):\n",
    "    data.to_csv(filename)\n",
    "\n",
    "def load_data_csv(filename): \n",
    "    data = pd.read_csv(filename, index_col=0)\n",
    "    return data\n",
    "\n",
    "def stock_train_test_split(returns, test_size=0.2):\n",
    "    train_data, test_data = train_test_split(returns, test_size=test_size, shuffle=False)\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "def run_garch(data, p, q, dist = 'normal', save = False):\n",
    "    percent_log_return = data*100\n",
    "    garch = arch_model(percent_log_return, p=p, q=q, dist=dist)\n",
    "    res = garch.fit(disp=\"off\")\n",
    "    if save:\n",
    "        save_garch_model([garch, res],  \"saved_models/garch_and_fit_\" + data.name + \".pkl\")    \n",
    "    return garch, res\n",
    "\n",
    "\n",
    "def run_simulation(garch, garch_parameters, num_simulation_days):\n",
    "    sim = garch.simulate(garch_parameters, num_simulation_days)\n",
    "    return sim['data']\n",
    "\n",
    "def simulate_many_episodes(data, p, q, dist='normal', num_days = 750, num_simulation_episodes = 50, test_size = 0.2, \n",
    "                            initial_price = 100, load_model = False, save = False):\n",
    "\n",
    "    train_simulations = int(num_simulation_episodes * (1 - test_size))\n",
    "    test_simulations = num_simulation_episodes - train_simulations\n",
    "\n",
    "    sim_df_train = pd.DataFrame(index=range(num_days + 1), columns=range(train_simulations))\n",
    "    sim_df_test = pd.DataFrame(index=range(num_days + 1), columns=range(test_simulations))\n",
    "\n",
    "    if load_model:\n",
    "        models = load_garch_model([garch, res],  \"saved_models/garch_and_fit_\" + data.name + \".pkl\")\n",
    "        garch, res = models[0], models[1]\n",
    "    else:\n",
    "        garch, res = run_garch(data, p, q, dist, save)\n",
    "\n",
    "    for i in range(num_simulation_episodes):\n",
    "        simulation = run_simulation(garch, res.params, num_days)\n",
    "        simulated_log_returns = simulation / 100\n",
    "        simulated_returns = np.exp(simulated_log_returns) - 1\n",
    "        simulated_prices = initial_price * (1 + simulated_returns).cumprod()\n",
    "        simulated_prices_with_initial = pd.concat([pd.Series([initial_price]), pd.Series(simulated_prices)], ignore_index=True)\n",
    "\n",
    "        # Split the simulations into training and testing sets\n",
    "        if i < train_simulations:\n",
    "            sim_df_train[i] = simulated_prices_with_initial\n",
    "        else:\n",
    "            sim_df_test[i - train_simulations] = simulated_prices_with_initial\n",
    "\n",
    "        save_data_csv(sim_df_train, \"data/sim_train_\" + data.name + \".csv\")\n",
    "        save_data_csv(sim_df_test, \"data/sim_test_\" + data.name + \".csv\")\n",
    "\n",
    "    return sim_df_train, sim_df_test\n",
    "\n",
    "\n",
    "def save_garch_model(fitted_models, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(fitted_models, f)\n",
    "\n",
    "def load_garch_model(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        fitted_models = pickle.load(f)\n",
    "    return fitted_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_simulation_data(tickers, folder_path):\n",
    "    stock_data_dict = {}\n",
    "    for ticker in tickers:\n",
    "        # Load training and testing data for each ticker\n",
    "        train_file = f'data/sim_train_{ticker}.csv'\n",
    "        test_file = f'data/sim_test_{ticker}.csv'\n",
    "        if os.path.exists(train_file) and os.path.exists(test_file):\n",
    "            train_data = pd.read_csv(train_file, index_col=0)\n",
    "            test_data = pd.read_csv(test_file, index_col=0)\n",
    "            stock_data_dict[ticker] = {'train': train_data, 'test': test_data}\n",
    "        else:\n",
    "            print(f\"File not found for ticker: {ticker}\")\n",
    "    return stock_data_dict\n",
    "\n",
    "\n",
    "def get_combined_simulation(stock_data_dict, simulation_index, set_type='train'):\n",
    "    combined_data = []\n",
    "    for stock in stock_data_dict.keys():\n",
    "        # Access either 'train' or 'test' data and get the column specified by simulation_index\n",
    "        stock_data = stock_data_dict[stock][set_type]\n",
    "        combined_data.append(stock_data.iloc[:, simulation_index].values)\n",
    "    return np.array(combined_data).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stock in train:\n",
    "    print(f\"Simulating data for {stock}...\")\n",
    "    sim_df_train, sim_df_test = gd.simulate_many_episodes(train[stock], 1, 1, dist='normal', num_days = num_simulation_days, \n",
    "                                                        num_simulation_episodes = num_simulation_episodes, test_size = 0.2, \n",
    "                                                        initial_price = 100, load_model = False, save = True)\n",
    "\n",
    "                                                        \n",
    "    print(f\"Simulated data for {stock} generated successfully!\")\n",
    "    pl.plot_simulations(sim_df_train, title=\"Training Simulations\")\n",
    "    pl.plot_simulations(sim_df_test, title=\"Testing Simulations\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Constant Mean(constant: yes, no. of exog: 0, volatility: GARCH(p: 1, q: 1), distribution: Normal distribution), id: 0x1cf78f66b90,\n",
       "                      Constant Mean - GARCH Model Results                      \n",
       " ==============================================================================\n",
       " Dep. Variable:                   MSFT   R-squared:                       0.000\n",
       " Mean Model:             Constant Mean   Adj. R-squared:                  0.000\n",
       " Vol Model:                      GARCH   Log-Likelihood:               -9574.85\n",
       " Distribution:                  Normal   AIC:                           19157.7\n",
       " Method:            Maximum Likelihood   BIC:                           19183.8\n",
       "                                         No. Observations:                 5030\n",
       " Date:                Tue, Oct 22 2024   Df Residuals:                     5029\n",
       " Time:                        23:38:05   Df Model:                            1\n",
       "                                 Mean Model                                \n",
       " ==========================================================================\n",
       "                  coef    std err          t      P>|t|    95.0% Conf. Int.\n",
       " --------------------------------------------------------------------------\n",
       " mu             0.0682  2.062e-02      3.307  9.421e-04 [2.778e-02,  0.109]\n",
       "                               Volatility Model                             \n",
       " ===========================================================================\n",
       "                  coef    std err          t      P>|t|     95.0% Conf. Int.\n",
       " ---------------------------------------------------------------------------\n",
       " omega          0.0478  3.825e-02      1.250      0.211 [-2.716e-02,  0.123]\n",
       " alpha[1]       0.0612  3.537e-02      1.730  8.357e-02 [-8.121e-03,  0.131]\n",
       " beta[1]        0.9248  4.344e-02     21.286 1.520e-100    [  0.840,  1.010]\n",
       " ===========================================================================\n",
       " \n",
       " Covariance estimator: robust\n",
       " ARCHModelResult, id: 0x1cf7b29b7f0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Garch model\n",
    "model = gd.load_garch_model(\"saved_models/garch_and_fit_MSFT.pkl\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "from data_scripts import generate_data as gd\n",
    "from data_scripts import plotting as pl\n",
    "\n",
    "tickers = ['MSFT', 'TGT', 'QCOM', 'MU', 'CAT']\n",
    "\n",
    "\n",
    "# Load simulation data for the selected stocks\n",
    "stock_data_dict = gd.load_simulation_data(tickers)\n",
    "\n",
    "# Get the combined training simulation data for the selected stocks\n",
    "combined_train_data = gd.get_combined_simulation(stock_data_dict, simulation_index=18, set_type='train')\n",
    "\n",
    "pl.plot_one_combined_simulation(combined_train_data, tickers, 'train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from trading_envs.trading_env import TradingEnv\n",
    "from models.ddpg_agent import Agent\n",
    "\n",
    "\n",
    "# Load simulation data for the selected stocks\n",
    "stock_data_dict = gd.load_simulation_data(tickers)\n",
    "\n",
    "# Get the combined training simulation data for the selected stocks\n",
    "combined_train_data = gd.get_combined_simulation(stock_data_dict, simulation_index=0, set_type='train')\n",
    "\n",
    "\n",
    "# Initialize variables\n",
    "test_size = 0.2\n",
    "train_simulations = int(num_simulation_episodes * (1 - test_size))\n",
    "test_simulations = num_simulation_episodes - train_simulations\n",
    "\n",
    "\n",
    "num_episodes = train_simulations\n",
    "max_steps_per_episode = num_simulation_days \n",
    "training_performance = []\n",
    "batch_size=64\n",
    "replay_start_size = 100\n",
    "\n",
    "\n",
    "train_simulation_index = 0\n",
    "train_simulation_data = gd.get_combined_simulation(stock_data_dict, simulation_index=train_simulation_index, set_type='train')\n",
    "\n",
    "\n",
    "env = TradingEnv(stock_data=train_simulation_data)\n",
    "\n",
    "agent = Agent(alpha=0.0001, beta=0.001, input_dims=[env.observation_space.shape[0]], \n",
    "                tau=0.001, env=env, batch_size=64, layer1_size=400, layer2_size=300, \n",
    "                n_actions=env.action_space.shape[0])\n",
    "\n",
    "scores = []\n",
    "\n",
    "wealth = []\n",
    "\n",
    "# Training loop only one time    \n",
    "for episode in range(num_episodes):\n",
    "    episode_wealth = []\n",
    "\n",
    "\n",
    "    train_simulation_index = episode # random.choice(train_simulations)\n",
    "    print(f\"Training on simulation {train_simulation_index + 1} of {num_episodes}\")\n",
    "    train_simulation_data = gd.get_combined_simulation(stock_data_dict, simulation_index=train_simulation_index, set_type='train')\n",
    "\n",
    "    # Set the new environment with this training data\n",
    "    env = TradingEnv(stock_data=train_simulation_data)\n",
    "\n",
    "    # Reset the environment and start a new episode\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    #while not done:\n",
    "    while not done:\n",
    "        action = agent.choose_action(state)\n",
    "        state_, reward, done, _, _ = env.step(action)\n",
    "        agent.remember(state, action, reward, state_, done)\n",
    "        agent.learn()\n",
    "        score += reward\n",
    "        state = state_\n",
    "\n",
    "        episode_wealth.append(env.get_portfolio_value())\n",
    "\n",
    "        env.render()\n",
    "    \n",
    "    wealth.append(episode_wealth)\n",
    "    training_performance.append(score)\n",
    "\n",
    "# Save the model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Plot the training performance\n",
    "plt.plot(training_performance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the different wealth trajectories\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(num_episodes):\n",
    "    plt.plot(wealth[i], label=f\"Episode {i+1}\")\n",
    "    plt.title(\"Wealth Trajectories for Training Episodes\")\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Portfolio Value\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load simulation data for the selected stocks\n",
    "stock_data_dict = gd.load_simulation_data(tickers)\n",
    "\n",
    "# Get the combined training simulation data for the selected stocks\n",
    "combined_train_data = gd.get_combined_simulation(stock_data_dict, simulation_index=7, set_type='train')\n",
    "\n",
    "pl.plot_one_combined_simulation(combined_train_data, tickers, 'train')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
